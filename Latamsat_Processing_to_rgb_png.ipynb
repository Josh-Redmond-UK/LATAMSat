{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting s2cloudless\n",
      "  Obtaining dependency information for s2cloudless from https://files.pythonhosted.org/packages/72/53/a535d72eb57667f8e408013c85fce518516092a63887040888076cf32a07/s2cloudless-1.7.1-py3-none-any.whl.metadata\n",
      "  Using cached s2cloudless-1.7.1-py3-none-any.whl.metadata (26 kB)\n",
      "Collecting lightgbm>=2.0.11 (from s2cloudless)\n",
      "  Using cached lightgbm-4.1.0.tar.gz (1.7 MB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /Users/joshredmond/miniconda3/envs/tensorflowMac/lib/python3.10/site-packages (from s2cloudless) (1.24.3)\n",
      "Collecting opencv-python-headless (from s2cloudless)\n",
      "  Obtaining dependency information for opencv-python-headless from https://files.pythonhosted.org/packages/12/0f/b87324db284c54d1d1a1c1242a128fb18515915d124325784c90f23d8ef5/opencv_python_headless-4.8.1.78-cp37-abi3-macosx_11_0_arm64.whl.metadata\n",
      "  Using cached opencv_python_headless-4.8.1.78-cp37-abi3-macosx_11_0_arm64.whl.metadata (19 kB)\n",
      "Collecting sentinelhub>=3.9.0 (from s2cloudless)\n",
      "  Obtaining dependency information for sentinelhub>=3.9.0 from https://files.pythonhosted.org/packages/b0/62/7520804a7ea9f5f5a23784bbf7f5299bca37aba2055c52d4611e413d765b/sentinelhub-3.9.3-py3-none-any.whl.metadata\n",
      "  Using cached sentinelhub-3.9.3-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: typing-extensions in /Users/joshredmond/miniconda3/envs/tensorflowMac/lib/python3.10/site-packages (from s2cloudless) (4.5.0)\n",
      "Requirement already satisfied: scipy in /Users/joshredmond/miniconda3/envs/tensorflowMac/lib/python3.10/site-packages (from lightgbm>=2.0.11->s2cloudless) (1.11.2)\n",
      "Collecting aenum>=2.1.4 (from sentinelhub>=3.9.0->s2cloudless)\n",
      "  Obtaining dependency information for aenum>=2.1.4 from https://files.pythonhosted.org/packages/d0/fa/ca0c66b388624ba9dbbf35aab3a9f326bfdf5e56a7237fe8f1b600da6864/aenum-3.1.15-py3-none-any.whl.metadata\n",
      "  Using cached aenum-3.1.15-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: click in /Users/joshredmond/miniconda3/envs/tensorflowMac/lib/python3.10/site-packages (from sentinelhub>=3.9.0->s2cloudless) (8.1.7)\n",
      "Collecting dataclasses-json (from sentinelhub>=3.9.0->s2cloudless)\n",
      "  Obtaining dependency information for dataclasses-json from https://files.pythonhosted.org/packages/21/1f/1cff009cff64420572b9f75b70e4a054095719179a172297dfdd65843162/dataclasses_json-0.6.1-py3-none-any.whl.metadata\n",
      "  Using cached dataclasses_json-0.6.1-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: oauthlib in /Users/joshredmond/miniconda3/envs/tensorflowMac/lib/python3.10/site-packages (from sentinelhub>=3.9.0->s2cloudless) (3.2.2)\n",
      "Requirement already satisfied: pillow>=9.2.0 in /Users/joshredmond/miniconda3/envs/tensorflowMac/lib/python3.10/site-packages (from sentinelhub>=3.9.0->s2cloudless) (10.0.0)\n",
      "Collecting pyproj>=2.2.0 (from sentinelhub>=3.9.0->s2cloudless)\n",
      "  Obtaining dependency information for pyproj>=2.2.0 from https://files.pythonhosted.org/packages/18/86/2e7cb9de40492f1bafbf11f4c9072edc394509a40b5e4c52f8139546f039/pyproj-3.6.1-cp310-cp310-macosx_11_0_arm64.whl.metadata\n",
      "  Using cached pyproj-3.6.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: python-dateutil in /Users/joshredmond/miniconda3/envs/tensorflowMac/lib/python3.10/site-packages (from sentinelhub>=3.9.0->s2cloudless) (2.8.2)\n",
      "Requirement already satisfied: requests-oauthlib>=1.0.0 in /Users/joshredmond/miniconda3/envs/tensorflowMac/lib/python3.10/site-packages (from sentinelhub>=3.9.0->s2cloudless) (1.3.1)\n",
      "Requirement already satisfied: requests>=2.27.0 in /Users/joshredmond/miniconda3/envs/tensorflowMac/lib/python3.10/site-packages (from sentinelhub>=3.9.0->s2cloudless) (2.31.0)\n",
      "Collecting shapely (from sentinelhub>=3.9.0->s2cloudless)\n",
      "  Obtaining dependency information for shapely from https://files.pythonhosted.org/packages/14/c8/0747225a0fa3f2b45cf9e6e5eef51f4b9ec3777f0eb2e594a6c90ff4ab53/shapely-2.0.2-cp310-cp310-macosx_11_0_arm64.whl.metadata\n",
      "  Using cached shapely-2.0.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: tifffile>=2020.9.30 in /Users/joshredmond/miniconda3/envs/tensorflowMac/lib/python3.10/site-packages (from sentinelhub>=3.9.0->s2cloudless) (2023.8.30)\n",
      "Requirement already satisfied: tomli in /Users/joshredmond/miniconda3/envs/tensorflowMac/lib/python3.10/site-packages (from sentinelhub>=3.9.0->s2cloudless) (2.0.1)\n",
      "Collecting tomli-w (from sentinelhub>=3.9.0->s2cloudless)\n",
      "  Using cached tomli_w-1.0.0-py3-none-any.whl (6.0 kB)\n",
      "Requirement already satisfied: tqdm in /Users/joshredmond/miniconda3/envs/tensorflowMac/lib/python3.10/site-packages (from sentinelhub>=3.9.0->s2cloudless) (4.66.1)\n",
      "Collecting utm (from sentinelhub>=3.9.0->s2cloudless)\n",
      "  Using cached utm-0.7.0-py3-none-any.whl\n",
      "Requirement already satisfied: certifi in /Users/joshredmond/miniconda3/envs/tensorflowMac/lib/python3.10/site-packages (from pyproj>=2.2.0->sentinelhub>=3.9.0->s2cloudless) (2023.7.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/joshredmond/miniconda3/envs/tensorflowMac/lib/python3.10/site-packages (from requests>=2.27.0->sentinelhub>=3.9.0->s2cloudless) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/joshredmond/miniconda3/envs/tensorflowMac/lib/python3.10/site-packages (from requests>=2.27.0->sentinelhub>=3.9.0->s2cloudless) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/joshredmond/miniconda3/envs/tensorflowMac/lib/python3.10/site-packages (from requests>=2.27.0->sentinelhub>=3.9.0->s2cloudless) (1.26.16)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->sentinelhub>=3.9.0->s2cloudless)\n",
      "  Obtaining dependency information for marshmallow<4.0.0,>=3.18.0 from https://files.pythonhosted.org/packages/ed/3c/cebfdcad015240014ff08b883d1c0c427f2ba45ae8c6572851b6ef136cad/marshmallow-3.20.1-py3-none-any.whl.metadata\n",
      "  Using cached marshmallow-3.20.1-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json->sentinelhub>=3.9.0->s2cloudless)\n",
      "  Obtaining dependency information for typing-inspect<1,>=0.4.0 from https://files.pythonhosted.org/packages/65/f3/107a22063bf27bdccf2024833d3445f4eea42b2e598abfbd46f6a63b6cb0/typing_inspect-0.9.0-py3-none-any.whl.metadata\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/joshredmond/miniconda3/envs/tensorflowMac/lib/python3.10/site-packages (from python-dateutil->sentinelhub>=3.9.0->s2cloudless) (1.16.0)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/joshredmond/miniconda3/envs/tensorflowMac/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->sentinelhub>=3.9.0->s2cloudless) (23.1)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json->sentinelhub>=3.9.0->s2cloudless)\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Using cached s2cloudless-1.7.1-py3-none-any.whl (4.8 MB)\n",
      "Using cached sentinelhub-3.9.3-py3-none-any.whl (245 kB)\n",
      "Using cached opencv_python_headless-4.8.1.78-cp37-abi3-macosx_11_0_arm64.whl (33.1 MB)\n",
      "Using cached aenum-3.1.15-py3-none-any.whl (137 kB)\n",
      "Using cached pyproj-3.6.1-cp310-cp310-macosx_11_0_arm64.whl (4.9 MB)\n",
      "Using cached dataclasses_json-0.6.1-py3-none-any.whl (27 kB)\n",
      "Using cached shapely-2.0.2-cp310-cp310-macosx_11_0_arm64.whl (1.3 MB)\n",
      "Using cached marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Building wheels for collected packages: lightgbm\n",
      "  Building wheel for lightgbm (pyproject.toml) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for lightgbm \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[46 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m 2023-11-03 09:37:56,862 - scikit_build_core - INFO - CMake version: 3.27.7\n",
      "  \u001b[31m   \u001b[0m \u001b[92m***\u001b[0m \u001b[1m\u001b[92mscikit-build-core 0.6.0\u001b[0m using \u001b[94mCMake 3.27.7\u001b[0m \u001b[91m(wheel)\u001b[0m\u001b[0m\n",
      "  \u001b[31m   \u001b[0m 2023-11-03 09:37:56,865 - scikit_build_core - INFO - Build directory: /private/var/folders/p4/txj2zhrx5vx9ynlpynxc19980000gn/T/tmplnik2n_5/build\n",
      "  \u001b[31m   \u001b[0m \u001b[92m***\u001b[0m \u001b[1mConfiguring CMake...\u001b[0m\n",
      "  \u001b[31m   \u001b[0m 2023-11-03 09:37:57,148 - scikit_build_core - INFO - Ninja version: 1.11.1\n",
      "  \u001b[31m   \u001b[0m 2023-11-03 09:37:57,149 - scikit_build_core - WARNING - libdir/ldlibrary: /Users/joshredmond/miniconda3/envs/tensorflowMac/lib/libpython3.10.a is not a real file!\n",
      "  \u001b[31m   \u001b[0m 2023-11-03 09:37:57,149 - scikit_build_core - WARNING - Can't find a Python library, got libdir=/Users/joshredmond/miniconda3/envs/tensorflowMac/lib, ldlibrary=libpython3.10.a, multiarch=darwin, masd=None\n",
      "  \u001b[31m   \u001b[0m loading initial cache file /var/folders/p4/txj2zhrx5vx9ynlpynxc19980000gn/T/tmplnik2n_5/build/CMakeInit.txt\n",
      "  \u001b[31m   \u001b[0m \u001b[0mCMake Deprecation Warning at CMakeLists.txt:35 (cmake_minimum_required):\n",
      "  \u001b[31m   \u001b[0m   Compatibility with CMake < 3.5 will be removed from a future version of\n",
      "  \u001b[31m   \u001b[0m   CMake.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m   Update the VERSION argument <min> value or use a ...<max> suffix to tell\n",
      "  \u001b[31m   \u001b[0m   CMake that the project does not need compatibility with older versions.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \u001b[0m\n",
      "  \u001b[31m   \u001b[0m -- The C compiler identification is AppleClang 14.0.3.14030022\n",
      "  \u001b[31m   \u001b[0m -- The CXX compiler identification is AppleClang 14.0.3.14030022\n",
      "  \u001b[31m   \u001b[0m -- Detecting C compiler ABI info\n",
      "  \u001b[31m   \u001b[0m -- Detecting C compiler ABI info - done\n",
      "  \u001b[31m   \u001b[0m -- Check for working C compiler: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/cc - skipped\n",
      "  \u001b[31m   \u001b[0m -- Detecting C compile features\n",
      "  \u001b[31m   \u001b[0m -- Detecting C compile features - done\n",
      "  \u001b[31m   \u001b[0m -- Detecting CXX compiler ABI info\n",
      "  \u001b[31m   \u001b[0m -- Detecting CXX compiler ABI info - done\n",
      "  \u001b[31m   \u001b[0m -- Check for working CXX compiler: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/c++ - skipped\n",
      "  \u001b[31m   \u001b[0m -- Detecting CXX compile features\n",
      "  \u001b[31m   \u001b[0m -- Detecting CXX compile features - done\n",
      "  \u001b[31m   \u001b[0m -- Could NOT find OpenMP_C (missing: OpenMP_C_FLAGS OpenMP_C_LIB_NAMES)\n",
      "  \u001b[31m   \u001b[0m -- Could NOT find OpenMP_CXX (missing: OpenMP_CXX_FLAGS OpenMP_CXX_LIB_NAMES)\n",
      "  \u001b[31m   \u001b[0m -- Could NOT find OpenMP (missing: OpenMP_C_FOUND OpenMP_CXX_FOUND)\n",
      "  \u001b[31m   \u001b[0m -- Found OpenMP_C: -Xpreprocessor -fopenmp -I/include\n",
      "  \u001b[31m   \u001b[0m -- Found OpenMP_CXX: -Xpreprocessor -fopenmp -I/include\n",
      "  \u001b[31m   \u001b[0m -- Found OpenMP: TRUE\n",
      "  \u001b[31m   \u001b[0m -- Performing Test MM_PREFETCH\n",
      "  \u001b[31m   \u001b[0m -- Performing Test MM_PREFETCH - Failed\n",
      "  \u001b[31m   \u001b[0m -- Performing Test MM_MALLOC\n",
      "  \u001b[31m   \u001b[0m -- Performing Test MM_MALLOC - Success\n",
      "  \u001b[31m   \u001b[0m -- Using _mm_malloc\n",
      "  \u001b[31m   \u001b[0m -- Configuring done (0.8s)\n",
      "  \u001b[31m   \u001b[0m -- Generating done (0.0s)\n",
      "  \u001b[31m   \u001b[0m -- Build files have been written to: /var/folders/p4/txj2zhrx5vx9ynlpynxc19980000gn/T/tmplnik2n_5/build\n",
      "  \u001b[31m   \u001b[0m \u001b[92m***\u001b[0m \u001b[1mBuilding project with \u001b[94mNinja\u001b[0m...\u001b[0m\n",
      "  \u001b[31m   \u001b[0m ninja: error: '/lib/libomp.dylib', needed by '/private/var/folders/p4/txj2zhrx5vx9ynlpynxc19980000gn/T/pip-install-x8q8v9wt/lightgbm_64577c9981dd44d8b2c4e24b10525355/lib_lightgbm.so', missing and no known rule to make it\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \u001b[91m\u001b[1m*** CMake build failed\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31m  ERROR: Failed building wheel for lightgbm\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25hFailed to build lightgbm\n",
      "\u001b[31mERROR: Could not build wheels for lightgbm, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install s2cloudless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kDQEyEj4apxC",
    "outputId": "483ed313-1148-4883-ed12-ffd514b61daa"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "a7WhOzURLGFA"
   },
   "outputs": [],
   "source": [
    "def get_lulc_class(path):\n",
    "  splits = path.split('/')\n",
    "  return splits[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "tmfApOIMT4XS"
   },
   "outputs": [],
   "source": [
    "def multispectral_to_rgb(raster, optical_maximum = 2000):\n",
    "\n",
    "  r = raster[:, :, 3]\n",
    "  g = raster[:, :, 2]\n",
    "  b = raster[:, :, 1]\n",
    "\n",
    "  rgb_raster = np.stack([r, g, b], axis=2)\n",
    "  rgb_raster = np.nan_to_num(rgb_raster)\n",
    "  rgb_raster = np.log(rgb_raster)\n",
    "  min = np.percentile(rgb_raster.flatten(), 1)\n",
    "  max = np.percentile(rgb_raster.flatten(), 99)\n",
    "  rgb_raster = 255 * (rgb_raster - min)/(max-min)\n",
    "  \n",
    "  #rgb_raster = rgb_raster/np.nanmax(raster)\n",
    "  #rgb_raster = np.around(rgb_raster*255)\n",
    "  rgb_raster = np.nan_to_num(np.clip(rgb_raster, 0, 255)).astype(int)\n",
    "  return rgb_raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "classDictionary = {30: 'Herbaceous Vegetation',\n",
    "20: 'Shrubs',\n",
    "40: 'Agricultural Land',\n",
    "50: 'Urban Areas',\n",
    "60: 'Bare Earth and Sparse Vegetation',\n",
    "70: 'Snow and Ice',\n",
    "80: 'Permanent Water Bodies',\n",
    "90: 'Herbaceous Wetland',\n",
    "100: 'Moss and Lichen',\n",
    "111: 'Closed Evergreen Needle Leaf Forest',\n",
    "112: 'Closed Evergreen Broad Leaf Forest',\n",
    "113: 'Closed Deciduous Needle Leaft Forest',\n",
    "114: 'Closed Deciduous Broad Leaf Forest',\n",
    "115: 'Closed Mixed Forest',\n",
    "116: 'Other Closed Forest',\n",
    "121: 'Open Evergreen Needle Leaf Forest',\n",
    "122: 'Open Evergreen Broad Leaf Forest',\n",
    "123: 'Open Deciduous Needle Leaft Forest',\n",
    "124: 'Open Deciduous Broad Leaf Forest',\n",
    "125: 'Open Mixed Forest',\n",
    "126: 'Other Open Forest',\n",
    "200: 'Oceans, Seas'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "Zdh1hcFLVYm-"
   },
   "outputs": [],
   "source": [
    "def rescale_image(raster):\n",
    "  raster = np.nan_to_num(raster)\n",
    "  max_val = np.nanmax(raster)\n",
    "  mid_val = max_val/2\n",
    "  rescaled = np.nan_to_num((raster-mid_val)/(mid_val))\n",
    "  return np.clip(rescaled, -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "09GjC2UXWAv6"
   },
   "outputs": [],
   "source": [
    "def rio_to_channels_last(raster):\n",
    "  return raster.transpose((1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "6UylQeatXsWU"
   },
   "outputs": [],
   "source": [
    "def get_array(path):\n",
    "  _r = tifffile.imread(path)\n",
    "  #arr = rio_to_channels_last(_r)\n",
    "  return _r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "piJ9G82aYzRR"
   },
   "outputs": [],
   "source": [
    "def get_image_paths(top_level_path):\n",
    "  ecoregion_folders = glob.glob(top_level_path+'/*')\n",
    "  img_paths = []\n",
    "  for ec_dir in ecoregion_folders:\n",
    "    img_paths += glob.glob(ec_dir+'*/*.tif')\n",
    "  return img_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecoregion_paths = 'latamSatData/DownloadedDataset/*'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Done\n",
      "10000 Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p4/txj2zhrx5vx9ynlpynxc19980000gn/T/ipykernel_19417/3141652692.py:12: RuntimeWarning: invalid value encountered in divide\n",
      "  rgb_raster = 255 * (rgb_raster - min)/(max-min)\n",
      "/var/folders/p4/txj2zhrx5vx9ynlpynxc19980000gn/T/ipykernel_19417/3141652692.py:12: RuntimeWarning: divide by zero encountered in divide\n",
      "  rgb_raster = 255 * (rgb_raster - min)/(max-min)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000 Done\n",
      "30000 Done\n",
      "40000 Done\n",
      "50000 Done\n",
      "60000 Done\n",
      "70000 Done\n",
      "80000 Done\n",
      "90000 Done\n",
      "100000 Done\n",
      "110000 Done\n",
      "120000 Done\n",
      "130000 Done\n",
      "140000 Done\n",
      "150000 Done\n",
      "160000 Done\n",
      "170000 Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p4/txj2zhrx5vx9ynlpynxc19980000gn/T/ipykernel_19417/3141652692.py:9: RuntimeWarning: divide by zero encountered in log\n",
      "  rgb_raster = np.log(rgb_raster)\n",
      "/Users/joshredmond/miniconda3/envs/tensorflowMac/lib/python3.10/site-packages/numpy/lib/function_base.py:4573: RuntimeWarning: invalid value encountered in subtract\n",
      "  diff_b_a = subtract(b, a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180000 Done\n",
      "190000 Done\n",
      "200000 Done\n",
      "210000 Done\n",
      "220000 Done\n",
      "230000 Done\n",
      "240000 Done\n",
      "250000 Done\n",
      "260000 Done\n",
      "270000 Done\n",
      "280000 Done\n",
      "290000 Done\n",
      "300000 Done\n",
      "310000 Done\n"
     ]
    }
   ],
   "source": [
    "img_paths = get_image_paths(ecoregion_paths)\n",
    "for idx, p in enumerate(img_paths):\n",
    "    arr = get_array(p)\n",
    "    rgb = multispectral_to_rgb(arr)\n",
    "    rgb = rgb.astype(np.uint8)\n",
    "\n",
    "    split_string = p.split('/')\n",
    "    ecoregionName = split_string[2]\n",
    "    split_string[3] = classDictionary[int(split_string[3])]\n",
    "    split_string[1] = \"datasetRGB_rescaled\"\n",
    "    split_string[-1] = ecoregionName+ '_' + split_string[-1][:-4] + '.png'\n",
    "    split_string.insert(2, 'all')\n",
    "    split_string.pop(3)\n",
    "\n",
    "    filePath = os.path.join('/'.join(split_string))\n",
    "    dirPath = os.path.join('/'.join(split_string[:-1])+'/')\n",
    "    if not os.path.isdir(dirPath):\n",
    "        os.makedirs(dirPath)\n",
    "    \n",
    "    image = Image.fromarray(np.squeeze(rgb), mode=\"RGB\")\n",
    "    image.save(filePath)\n",
    "\n",
    "\n",
    "    if  idx % 10000 == 0:\n",
    "        print(idx, 'Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'latamSatData/datasetRGB_rescaled/all/Urban Areas/135_tile_255361.png'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filePath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'latamSatData/datasetRGB_rescaled/all/Urban Areas/'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wHHW6th6aJRr"
   },
   "outputs": [],
   "source": [
    "def prepare_for_training(ds, cache=True, batch_size=32, shuffle_buffer_size=1000):\n",
    "\n",
    "  # shuffle the dataset\n",
    "  #ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
    "  # Repeat forever\n",
    "  #ds = ds.repeat()\n",
    "  # split to batches\n",
    "  ds = ds.batch(batch_size)\n",
    "  # `prefetch` lets the dataset fetch batches in the background while the model\n",
    "  # is training.\n",
    "  ds = ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "  return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecoregion_paths = 'latamSatData/DownloadedDataset/*'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GY5wdB73GJY0",
    "outputId": "e1465613-1cfd-4b7d-a3d6-1b2819f533a9"
   },
   "outputs": [],
   "source": [
    "\n",
    "dataset = latamSatGenerator(ecoregion_paths, batch_size=1)\n",
    "#train_img_generator = dataset.random_image_generator(normalise=True, rgb=True, split=[0,60])\n",
    "#test_img_generator = dataset.random_image_generator(normalise=True, rgb=True, split=[61,90])\n",
    "#val_img_generator = dataset.random_image_generator(normalise=True, rgb=True,split=[91,100])\n",
    "train_img_generator = dataset.make_tf_dataset(normalise=True, rgb=False, supervised=True, split=[0,60])\n",
    "test_img_generator = dataset.make_tf_dataset(normalise=True, rgb=False, split=[61,70])\n",
    "val_img_generator = dataset.make_tf_dataset(normalise=True, rgb=False, split=[71,99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_ds_gen = dataset.random_image_generator(supervised=True, rgb=False, normalise=True, one_hot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_training(dataset, batch_size=32, cache='CachedDataset.cache'):\n",
    "    dataset = dataset.repeat()\n",
    "\n",
    "    dataset = dataset.batch(batch_size, drop_remainder=True)\n",
    "\n",
    "\n",
    "    #dataset = dataset.shuffle(64)\n",
    "\n",
    "    #dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_img_generator = prepare_for_training(val_img_generator, cache='valCahce.cache')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_generator = prepare_for_training(train_img_generator, cache='trainCache.cache')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_generator = prepare_for_training(test_img_generator, cache='testCache.cache')\n",
    "\n",
    "testreturn = next(val_img_generator.as_numpy_iterator())\n",
    "testreturn[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_channels = testreturn[0].shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1dRIUdk5N4UT"
   },
   "outputs": [],
   "source": [
    "num_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E0ch81ZHQckD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L3dZS7C6P6Fq"
   },
   "outputs": [],
   "source": [
    "img_path_len = len(dataset.img_paths)\n",
    "img_path_pct = np.floor(img_path_len/100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_epoch = (img_path_pct*60 // ds_batch_size) - 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_validation = (img_path_pct*10 // ds_batch_size) -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uq6hozOham5A"
   },
   "outputs": [],
   "source": [
    "#train_ds = prepare_for_training(img_generator, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jnWADBhaiBUz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qwV58-j7SnSB"
   },
   "outputs": [],
   "source": [
    "def make_model(input_shape, num_classes):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "\n",
    "    # Entry block\n",
    "    #x = layers.Rescaling(1.0 / 255)(inputs)\n",
    "    x = tf.keras.layers.Conv2D(128, 3, strides=2, padding=\"same\")(inputs)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "    previous_block_activation = x  # Set aside residual\n",
    "\n",
    "    for size in [256, 512, 768]:\n",
    "        x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "        x = tf.keras.layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "        x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "        x = tf.keras.layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "        x = tf.keras.layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = tf.keras.layers.Conv2D(size, 1, strides=2, padding=\"same\")(\n",
    "            previous_block_activation\n",
    "        )\n",
    "        x = tf.keras.layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    x = tf.keras.layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    if num_classes == 2:\n",
    "        activation = \"sigmoid\"\n",
    "        units = 1\n",
    "    else:\n",
    "        activation = \"softmax\"\n",
    "        units = num_classes\n",
    "\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    outputs = tf.keras.layers.Dense(units, activation=activation)(x)\n",
    "    return tf.keras.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "m = make_model(input_shape=(64,64,13), num_classes=19)\n",
    "tf.keras.utils.plot_model(m, show_shapes=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eFMYdCBROJqL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "md86UUYaVcqu"
   },
   "outputs": [],
   "source": [
    "\n",
    "m.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\"],\n",
    "    run_eagerly=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "REYzLMQjW8-I"
   },
   "outputs": [],
   "source": [
    "model_name = \"satellite-classification_xception\"\n",
    "model_path = os.path.join( model_name + \".h5\")\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(model_path, save_best_only=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    m.load_weights(model_path)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "uxd2GAcJXDPy",
    "outputId": "a2826415-34ca-43c2-b274-1cbe577cf298",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def recursive_train():\n",
    "    try:\n",
    "        m_history = m.fit(\n",
    "        train_img_generator,\n",
    "        validation_data = test_img_generator,\n",
    "        verbose=1, epochs=num_epochs,\n",
    "        steps_per_epoch=steps_epoch,\n",
    "        validation_steps = 25,\n",
    "    \n",
    "        callbacks=[model_checkpoint]\n",
    "        )\n",
    "    except:\n",
    "        #print('epoch', epochs)\n",
    "        pass\n",
    "        \n",
    "\n",
    "for i in range(1):\n",
    "    print('starting epoch', i)\n",
    "    #recursive_train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.load_weights(model_path)\n",
    "featureExtraction = tf.keras.Model(inputs=m.input,\n",
    "                                 outputs=m.layers[-2].output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cleanlab import Datalab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feats_2 = []\n",
    "classifications_2 = []\n",
    "imgs_2 = []\n",
    "pred_probs = []\n",
    "for i in range(100001, img_path_len):\n",
    "    img, probs = next(whole_ds_gen)\n",
    "    img = np.expand_dims(img, 0)\n",
    "    _f = featureExtraction.predict(img, verbose=0)\n",
    "    pred = m.predict(img, verbose=0)\n",
    "    feats_2.append(_f)\n",
    "    imgs_2.append(img)\n",
    "    pred_probs.append(pred)\n",
    "    \n",
    "    classifications_2.append(probs)\n",
    "    if i > 0 and i % 1000 == 0:\n",
    "        print(i, 'done')\n",
    "    if i > 0 and i % 10000 == 0:\n",
    "        data_to_clean = {'Images':np.squeeze(np.array(imgs_2)), 'Labels':np.array(classifications_2)}\n",
    "        lab = Datalab(data=data_to_clean, label_name=\"Labels\", image_key=\"Images\")\n",
    "        lab.find_issues(pred_probs=np.squeeze(np.array(pred_probs)), features=np.squeeze(np.array(feats_2)))\n",
    "        label_issues = lab.get_issues(\"label\")\n",
    "        label_issues.to_csv(f\"{i}_issues.csv\")\n",
    "        del(feats_2)\n",
    "        del(classifications_2)\n",
    "        del(imgs_2)\n",
    "        del(pred_probs)\n",
    "        feats_2 = []\n",
    "        classifications_2 = []\n",
    "        imgs_2 = []\n",
    "        pred_probs = []\n",
    "        \n",
    "\n",
    "data_to_clean = {'Images':np.squeeze(np.array(imgs_2)), 'Labels':np.array(classifications_2)}\n",
    "lab = Datalab(data=data_to_clean, label_name=\"Labels\", image_key=\"Images\")\n",
    "lab.find_issues(pred_probs=np.squeeze(np.array(pred_probs)), features=np.squeeze(np.array(feats_2)))\n",
    "label_issues = lab.get_issues(\"label\")\n",
    "label_issues.to_csv(f\"{i}_issues.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab\n",
    "#label_issues_df = label_issues.query(\"is_label_issue\").sort_values(\"label_score\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_full = feats+ feats_2\n",
    "classifications_full = classifications + classifications_2\n",
    "\n",
    "import pickle\n",
    "with open('featuresPickle.pickle', 'wb') as wf:\n",
    "    pickle.dump(feats_full, wf)\n",
    "\n",
    "with open('classesPickle.pickle', 'wb') as wc:\n",
    "    pickle.dump(classifications_full, wc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Done!')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
