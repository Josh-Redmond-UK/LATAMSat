{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcc40249-9aac-4d17-bae6-63e3a13d216c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds\n",
    "import glob\n",
    "import shutil\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2285839-6084-4dbf-bd78-b0121f1b617b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = 'latamSatData/datasetRGB_rescaled/*/'\n",
    "fileStrings = glob.glob(pattern)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ea63657-6dc5-44fe-b72a-ac0e1844e78b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['latamSatData/datasetRGB_rescaled/all/']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fileStrings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3eda69b-43ab-46f7-b6a9-d48ec60d6329",
   "metadata": {},
   "outputs": [],
   "source": [
    "classDictionary = {30: 'Herbaceous Vegetation',\n",
    "20: 'Shrubs',\n",
    "40: 'Agricultural Land',\n",
    "50: 'Urban Areas',\n",
    "60: 'Bare Earth/Sparse Vegetation',\n",
    "70: 'Snow and Ice',\n",
    "80: 'Permanent Water Bodies',\n",
    "90: 'Herbaceous Wetland',\n",
    "100: 'Moss and Lichen',\n",
    "111: 'Closed Evergreen Needle Leaf Forest',\n",
    "112: 'Closed Evergreen Broad Leaf Forest',\n",
    "113: 'Closed Deciduous Needle Leaft Forest',\n",
    "114: 'Closed Deciduous Broad Leaf Forest',\n",
    "115: 'Closed Mixed Forest',\n",
    "116: 'Other Closed Forest',\n",
    "121: 'Open Evergreen Needle Leaf Forest',\n",
    "122: 'Open Evergreen Broad Leaf Forest',\n",
    "123: 'Open Deciduous Needle Leaft Forest',\n",
    "124: 'Open Deciduous Broad Leaf Forest',\n",
    "125: 'Open Mixed Forest',\n",
    "126: 'Other Open Forest',\n",
    "200: 'Oceans, Seas'}\n",
    "\n",
    "#for idx, fs in enumerate(fileStrings):\n",
    "  #  parts = fs.split('/')\n",
    "  #  ecoregionCode = parts[-3]\n",
    "  #  filename = ecoregionCode + '_' + parts[-1] \n",
    "  #  parts[-1] = filename\n",
    "  #  parts[1] = topFolder\n",
    "  #  parts.pop(2)\n",
    "  #  className = classDictionary[int(parts[-2])]\n",
    "  #  parts[-2] = className\n",
    " #   newFile = '/'.join(parts)\n",
    " #   newDir = '/'.join(parts[:-1])\n",
    "#    if not os.path.exists(n#ewDir):\n",
    "#        os.makedirs(newDir)#\n",
    "\n",
    "#    shutil.copy(fs, newFile)\n",
    "#    if idx % 1000 == 0 :\n",
    "#        print(idx, 'done')\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11c774a1-469d-42a0-97f0-3e839926e490",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = glob.glob('latamSatData/datasetRGB_relabel/*/*')\n",
    "classes = [c.split('/')[-1] for c in classes]\n",
    "idxKeys = [i for i in range(len(classes))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c32b3dd0-6002-4607-9109-b818c3715e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "classnameDict = dict(zip(idxKeys, classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e561698a-a294-4516-82be-3fe1d82a8e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Open Evergreen Broad Leaf Forest',\n",
       " 1: 'Bare Earth Sparse Vegetation',\n",
       " 2: 'Permanent Water Bodies',\n",
       " 3: 'Closed Deciduous Broad Leaf Forest',\n",
       " 4: 'Open Mixed Forest',\n",
       " 5: 'Urban Areas',\n",
       " 6: 'Snow and Ice',\n",
       " 7: 'Oceans, Seas',\n",
       " 8: 'Closed Evergreen Needle Leaf Forest',\n",
       " 9: 'Agricultural Land',\n",
       " 10: 'Other Closed Forest',\n",
       " 11: 'Open Evergreen Needle Leaf Forest',\n",
       " 12: 'Shrubs',\n",
       " 13: 'Other Open Forest',\n",
       " 14: 'Closed Mixed Forest',\n",
       " 15: 'Open Deciduous Broad Leaf Forest',\n",
       " 16: 'Closed Evergreen Broad Leaf Forest',\n",
       " 17: 'Herbaceous Vegetation',\n",
       " 18: 'Herbaceous Wetland'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classnameDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd1ac03b-812b-4851-9f70-29d7b9531a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-25 19:58:14.501505: W tensorflow/tsl/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"NOT_FOUND: Could not locate the credentials file.\". Retrieving token from GCE failed with \"FAILED_PRECONDITION: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Could not resolve host: metadata.google.internal\".\n",
      "2023-10-25 19:58:17.173502: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2 Pro\n",
      "2023-10-25 19:58:17.173528: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2023-10-25 19:58:17.173533: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2023-10-25 19:58:17.173566: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-10-25 19:58:17.173583: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "folder = 'latamSatData/datasetRGB_rescaled/'\n",
    "\n",
    "builder = tfds.folder_dataset.ImageFolder(folder)\n",
    "base_dataset = builder.as_dataset()['all']\n",
    "filenames = []\n",
    "labels = []\n",
    "def onehot_encode(x):\n",
    "    x['label'] = tf.one_hot(x['label'], 19)\n",
    "    return x\n",
    "base_dataset = base_dataset.map(onehot_encode)\n",
    "base_dataset = base_dataset.shuffle(base_dataset.cardinality())\n",
    "base_dataset = base_dataset.batch(32)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76b0e9a1-6d43-4c45-91ab-88b7aed53df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_(dataset, test_size):\n",
    "    dataset = dataset.shuffle(dataset.cardinality())\n",
    "    pct_size = dataset.cardinality().numpy() / 100 \n",
    "    test_size = round(pct_size * test_size)\n",
    "    test_dataset = dataset.take(test_size)\n",
    "    train_dataset = dataset.skip(test_size)\n",
    "    return train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e2d6f2e-7e4b-450d-b18e-72e9ca4a892e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split_(base_dataset, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38522027-da11-4cce-93e9-36b5d0dd0564",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(input_shape, num_classes):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "\n",
    "    # Entry block\n",
    "    x = tf.keras.layers.Rescaling(1.0 / 255)(inputs)\n",
    "    x = tf.keras.layers.Conv2D(128, 3, strides=2, padding=\"same\")(inputs)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "    previous_block_activation = x  # Set aside residual\n",
    "\n",
    "    for size in [256, 512, 768]:\n",
    "        x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "        x = tf.keras.layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "        x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "        x = tf.keras.layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "        x = tf.keras.layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = tf.keras.layers.Conv2D(size, 1, strides=2, padding=\"same\")(\n",
    "            previous_block_activation\n",
    "        )\n",
    "        x = tf.keras.layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    x = tf.keras.layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    if num_classes == 2:\n",
    "        activation = \"sigmoid\"\n",
    "        units = 1\n",
    "    else:\n",
    "        activation = \"softmax\"\n",
    "        units = num_classes\n",
    "\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    outputs = tf.keras.layers.Dense(units, activation=activation)(x)\n",
    "    return tf.keras.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "m = make_model(input_shape=(64,64,3), num_classes=19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43bc46a0-faa0-4dd9-b5ee-77a753aead46",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"rgb_logscale_cleanlab_classification\",\n",
    "    save_weights_only=False,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52aefd08-ccdc-4123-971e-c929293d68e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "m.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\"],\n",
    "    run_eagerly=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0915b83d-ae98-48e9-946b-68f031a8666a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xy_training(x, y):\n",
    "    return x, y\n",
    "train = train.map(get_xy_training)\n",
    "test = train.map(get_xy_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75de3d1-2aff-4dd5-911a-1bceb9fee887",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c976545a-c549-4a83-b156-f05c9b406412",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b8539ee-8bfd-4a0a-845c-ea432372e61e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed34569a-4b6f-4747-a319-9c9714a3c48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-25 19:59:45.315961: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-10-25 19:59:55.404741: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 216095 of 298857\n",
      "2023-10-25 19:59:59.094695: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] Shuffle buffer filled.\n",
      "2023-10-25 19:59:59.096697: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 1 of 9340\n",
      "2023-10-25 20:00:04.235619: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 886/7472 [==>...........................] - ETA: 5:11 - loss: 2.2801 - accuracy: 0.2443"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_history \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m36\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mmodel_checkpoint_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflowMac/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflowMac/lib/python3.10/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflowMac/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflowMac/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflowMac/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflowMac/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflowMac/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflowMac/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflowMac/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflowMac/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_history = m.fit(train, epochs=36, validation_data=test, callbacks=[model_checkpoint_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a01aba-1533-4f17-ae50-3c1a762f9f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004e98a4-1bc8-4a7d-a083-f49316087ffc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34b58e8-328f-4cd3-a6bf-0a7f299e1cb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d012f0-2ec8-4618-a152-8a68daf64af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = tf.keras.models.load_model('base_model_for_cleanlab_v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7845fc79-59e4-488b-8b68-bd1ea5f44e03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f147def-a1a1-42bc-a684-25c36254bcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extraction = tf.keras.Model(m.input, m.layers[-3].output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb47b55-8a8e-4e05-aff0-65d6ab8d78d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class_to_int_dict = dict(zip(classnameDict.values(), classnameDict.keys()))\n",
    "class_to_int_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8565e99-7441-4ef6-9230-42f7c4a1ee77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cleanlab import Datalab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688eb4b6-3b67-4d57-be8e-2539b87aafb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6511c65a-8b1f-4163-9c7f-415c6f982964",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677a9887-fda5-4ff6-ba8c-c5f0aaa40537",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39cf548-5b3f-4126-bcdf-e6c48f787879",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1337de-6de2-41b8-a3b5-3c276f561260",
   "metadata": {},
   "outputs": [],
   "source": [
    "issues_list = []\n",
    "labs_list = []\n",
    "filepaths = []\n",
    "i = 1\n",
    "for batch in base_dataset:\n",
    "    print('batch', i)\n",
    "    images = batch['image'].numpy()\n",
    "    classes = batch['label'].numpy()\n",
    "    paths = batch['image/filename']\n",
    "    filepaths.append(paths)\n",
    "    classProb = m.predict(images, verbose=0)\n",
    "    predFeat= feature_extraction.predict(images, verbose=0)\n",
    "    data_to_clean = {'Images':np.squeeze(np.array(images)), 'Labels':np.argmax(classes, axis=1)}\n",
    "    lab = Datalab(data=data_to_clean, label_name=\"Labels\", image_key=\"Images\")\n",
    "    lab.find_issues(pred_probs=np.squeeze(np.array(classProb)), features=np.squeeze(np.array(predFeat)))\n",
    "    issues = lab.get_issues('label')\n",
    "    issues['filepath'] = paths\n",
    "    issues_list.append(issues)\n",
    "    labs_list.append(lab)\n",
    "    i += 1 \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b803b322-b724-4872-b083-3c3ca70b20f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_issues = pd.concat(issues_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11535745-33ac-44ed-8024-76a5d0b37f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_issues\n",
    "all_issues['given_label'] = all_issues['given_label'].map(classnameDict)\n",
    "all_issues['predicted_label'] = all_issues['predicted_label'].map(classnameDict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add4e2d4-03b5-4217-83e5-57b127adbedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_issues['filepath'] = all_issues['filepath'].apply(lambda x: x.decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841b9a3e-2e50-4b55-a8ed-95f17a0d19f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_issues[all_issues['is_label_issue']]\n",
    "\n",
    "def relabel_filepath(file_path, new_label):\n",
    "    file_path = file_path.split('/')\n",
    "    file_path[-2]=new_label\n",
    "    file_path = '/'.join(file_path)\n",
    "    return file_path\n",
    "all_issues['new_filepath'] = all_issues.apply(lambda x: relabel_filepath(x.filepath, x.predicted_label), axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a409ed0-7e78-4684-917f-a3d1232ce458",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def move_file(old_path, new_path):\n",
    "    shutil.move(old_path, new_path)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e941fac1-cb81-4c80-89f0-c794f55260fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171ee113-8375-49c2-9cda-cd4ccb42bce8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a256b90-2069-4591-af66-8d8f5a8b4b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f50475b-742c-4ee5-a11c-38f35f54af9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_issues.to_csv('relabel_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5136e1f0-dca1-4086-879d-17bedd33269d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relabel_images(filepaths, issues, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4280b759-a75a-4fff-8cd3-d3bd3dfa8fd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27094035-8626-442b-8886-531b3bd96e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "issues_list = []\n",
    "for i in range(len(labs_list)):\n",
    "    label_issues = labs_list[i].get_issues(\"label\")\n",
    "    label_issues = label_issues[label_issues['is_label_issue']]\n",
    "    label_issues['given_label'] = label_issues['given_label'].map(classnameDict)\n",
    "    label_issues['predicted_label'] = label_issues['predicted_label'].map(classnameDict)\n",
    "    issues_list.append(label_issues)\n",
    "label_issues = pd.concat(issues_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2450f07c-76ad-4813-8ddf-a0ab1377ede9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53d47f7-f29b-42c5-932f-6f00b703a572",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821e73bc-e087-4754-932c-0e8e69a54946",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_issues.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5155bfa-becb-44a1-88cb-5375db0bc9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b901e74-7c8b-449a-a760-4df40b076b2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4997986d-27b0-4c4b-b25c-1d6e0c1abc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b07e6f-2c11-4867-b544-d3b830247048",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_issues = all_issues[all_issues['is_label_issue']]\n",
    "adj = pd.crosstab(label_issues['given_label'], label_issues['predicted_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b670061f-b921-4e16-bf52-3fe06068464d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(adj)\n",
    "plt.xticks(range(len(adj.columns)), adj.columns,rotation='vertical')\n",
    "plt.ylabel('Given Label')\n",
    "plt.xlabel('New Label')\n",
    "plt.yticks(range(len(adj.index)), adj.index)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6e84ee-e0e8-48f3-ad38-f49132273504",
   "metadata": {},
   "outputs": [],
   "source": [
    "issues = label_issues[label_issues['is_label_issue']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288e164d-923a-41ed-973d-6298b127278a",
   "metadata": {},
   "outputs": [],
   "source": [
    "issues['given_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71d547f-e760-4ff7-9c8c-ac60189b1abe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
