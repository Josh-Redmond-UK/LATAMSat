{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kDQEyEj4apxC",
    "outputId": "483ed313-1148-4883-ed12-ffd514b61daa"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "a7WhOzURLGFA"
   },
   "outputs": [],
   "source": [
    "def get_lulc_class(path):\n",
    "  splits = path.split('/')\n",
    "  return splits[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "tmfApOIMT4XS"
   },
   "outputs": [],
   "source": [
    "def multispectral_to_rgb(raster, optical_maximum = 2000):\n",
    "\n",
    "  r = raster[:, :, 3]\n",
    "  g = raster[:, :, 2]\n",
    "  b = raster[:, :, 1]\n",
    "\n",
    "  rgb_raster = np.stack([r, g, b], axis=2)\n",
    "\n",
    "  #cast to uint and scale to 0/255\n",
    "\n",
    "  rgb_raster = rgb_raster/optical_maximum\n",
    "  rgb_raster = np.around(rgb_raster*255)\n",
    "  rgb_raster = np.clip(rgb_raster, 0, 255).astype(int)\n",
    "  return rgb_raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classDictionary = {30: 'Herbaceous Vegetation',\n",
    "20: 'Shrubs',\n",
    "40: 'Agricultural Land',\n",
    "50: 'Urban Areas',\n",
    "60: 'Bare Earth/Sparse Vegetation',\n",
    "70: 'Snow and Ice',\n",
    "80: 'Permanent Water Bodies',\n",
    "90: 'Herbaceous Wetland',\n",
    "100: 'Moss and Lichen',\n",
    "111: 'Closed Evergreen Needle Leaf Forest',\n",
    "112: 'Closed Evergreen Broad Leaf Forest',\n",
    "113: 'Closed Deciduous Needle Leaft Forest',\n",
    "114: 'Closed Deciduous Broad Leaf Forest',\n",
    "115: 'Closed Mixed Forest',\n",
    "116: 'Other Closed Forest',\n",
    "121: 'Open Evergreen Needle Leaf Forest',\n",
    "122: 'Open Evergreen Broad Leaf Forest',\n",
    "123: 'Open Deciduous Needle Leaft Forest',\n",
    "124: 'Open Deciduous Broad Leaf Forest',\n",
    "125: 'Open Mixed Forest',\n",
    "126: 'Other Open Forest',\n",
    "200: 'Oceans, Seas'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Zdh1hcFLVYm-"
   },
   "outputs": [],
   "source": [
    "def rescale_image(raster):\n",
    "  raster = np.nan_to_num(raster)\n",
    "  max_val = np.nanmax(raster)\n",
    "  mid_val = max_val/2\n",
    "  rescaled = np.nan_to_num((raster-mid_val)/(mid_val))\n",
    "  return np.clip(rescaled, -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "09GjC2UXWAv6"
   },
   "outputs": [],
   "source": [
    "def rio_to_channels_last(raster):\n",
    "  return raster.transpose((1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "6UylQeatXsWU"
   },
   "outputs": [],
   "source": [
    "def get_array(path):\n",
    "  _r = tifffile.imread(path)\n",
    "  #arr = rio_to_channels_last(_r)\n",
    "  return _r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "piJ9G82aYzRR"
   },
   "outputs": [],
   "source": [
    "def get_image_paths(top_level_path):\n",
    "  ecoregion_folders = glob.glob(top_level_path+'/*')\n",
    "  img_paths = []\n",
    "  for ec_dir in ecoregion_folders:\n",
    "    img_paths += glob.glob(ec_dir+'*/*.tif')\n",
    "  return img_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "iACm5bKtEkpN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "wHHW6th6aJRr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GY5wdB73GJY0",
    "outputId": "e1465613-1cfd-4b7d-a3d6-1b2819f533a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating paths\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-03 10:39:03.189535: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2 Pro\n",
      "2023-10-03 10:39:03.189561: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2023-10-03 10:39:03.189568: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2023-10-03 10:39:03.189634: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-10-03 10:39:03.189666: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "folder = 'latamSatData/datasetRGB'\n",
    "test_dataset = tfds.ImageFolder(folder)\n",
    "test_dataset = test_dataset.as_dataset(as_supervised=True, batch_size=32)\n",
    "for k in test_dataset.keys():\n",
    "    test_dataset[k] = test_dataset[k].map(lambda x, y: (x, tf.one_hot(y, depth=19)))\n",
    "base_dataset = test_dataset['0']\n",
    "for idx, k in enumerate(test_dataset.keys()):\n",
    "    if k != '0':\n",
    "        base_dataset = base_dataset.concatenate(test_dataset[k])\n",
    "    \n",
    "    \n",
    "del(test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_ds_gen = dataset.random_image_generator(supervised=True, rgb=False, normalise=True, one_hot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_training(dataset, batch_size=32, cache='CachedDataset.cache'):\n",
    "    dataset = dataset.repeat()\n",
    "\n",
    "    dataset = dataset.batch(batch_size, drop_remainder=True)\n",
    "\n",
    "\n",
    "    #dataset = dataset.shuffle(64)\n",
    "\n",
    "    #dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_img_generator = prepare_for_training(val_img_generator, cache='valCahce.cache')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_generator = prepare_for_training(train_img_generator, cache='trainCache.cache')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 19)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_img_generator = prepare_for_training(test_img_generator, cache='testCache.cache')\n",
    "\n",
    "testreturn = next(val_img_generator.as_numpy_iterator())\n",
    "testreturn[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_channels = testreturn[0].shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "1dRIUdk5N4UT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E0ch81ZHQckD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "L3dZS7C6P6Fq"
   },
   "outputs": [],
   "source": [
    "img_path_len = len(dataset.img_paths)\n",
    "img_path_pct = np.floor(img_path_len/100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_epoch = (img_path_pct*60 // ds_batch_size) - 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5882.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_validation = (img_path_pct*10 // ds_batch_size) -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "979.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "Uq6hozOham5A"
   },
   "outputs": [],
   "source": [
    "#train_ds = prepare_for_training(img_generator, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jnWADBhaiBUz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "qwV58-j7SnSB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "def make_model(input_shape, num_classes):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "\n",
    "    # Entry block\n",
    "    #x = layers.Rescaling(1.0 / 255)(inputs)\n",
    "    x = tf.keras.layers.Conv2D(128, 3, strides=2, padding=\"same\")(inputs)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "    previous_block_activation = x  # Set aside residual\n",
    "\n",
    "    for size in [256, 512, 768]:\n",
    "        x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "        x = tf.keras.layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "        x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "        x = tf.keras.layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "        x = tf.keras.layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = tf.keras.layers.Conv2D(size, 1, strides=2, padding=\"same\")(\n",
    "            previous_block_activation\n",
    "        )\n",
    "        x = tf.keras.layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    x = tf.keras.layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    if num_classes == 2:\n",
    "        activation = \"sigmoid\"\n",
    "        units = 1\n",
    "    else:\n",
    "        activation = \"softmax\"\n",
    "        units = num_classes\n",
    "\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    outputs = tf.keras.layers.Dense(units, activation=activation)(x)\n",
    "    return tf.keras.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "m = make_model(input_shape=(64,64,13), num_classes=19)\n",
    "tf.keras.utils.plot_model(m, show_shapes=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eFMYdCBROJqL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "md86UUYaVcqu"
   },
   "outputs": [],
   "source": [
    "\n",
    "m.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\"],\n",
    "    run_eagerly=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "REYzLMQjW8-I"
   },
   "outputs": [],
   "source": [
    "model_name = \"satellite-classification_xception\"\n",
    "model_path = os.path.join( model_name + \".h5\")\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(model_path, save_best_only=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    m.load_weights(model_path)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "uxd2GAcJXDPy",
    "outputId": "a2826415-34ca-43c2-b274-1cbe577cf298",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def recursive_train():\n",
    "    try:\n",
    "        m_history = m.fit(\n",
    "        train_img_generator,\n",
    "        validation_data = test_img_generator,\n",
    "        verbose=1, epochs=num_epochs,\n",
    "        steps_per_epoch=steps_epoch,\n",
    "        validation_steps = 25,\n",
    "    \n",
    "        callbacks=[model_checkpoint]\n",
    "        )\n",
    "    except:\n",
    "        #print('epoch', epochs)\n",
    "        pass\n",
    "        \n",
    "\n",
    "for i in range(1):\n",
    "    print('starting epoch', i)\n",
    "    #recursive_train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.load_weights(model_path)\n",
    "featureExtraction = tf.keras.Model(inputs=m.input,\n",
    "                                 outputs=m.layers[-2].output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cleanlab import Datalab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-03 10:39:07.793830: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-10-03 10:39:08.987484: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71000 done\n",
      "72000 done\n",
      "73000 done\n",
      "74000 done\n",
      "75000 done\n",
      "76000 done\n",
      "77000 done\n",
      "78000 done\n",
      "79000 done\n",
      "80000 done\n",
      "Finding label issues ...\n",
      "Finding outlier issues ...\n",
      "Fitting OOD estimator based on provided features ...\n",
      "Finding near_duplicate issues ...\n",
      "Finding non_iid issues ...\n",
      "Finding dark, light, low_information, odd_aspect_ratio, odd_size, grayscale, blurry images ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd78c58e04fa4a6881b3b96b105a026a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in checking for image issues: 'list' object has no attribute 'size'\n",
      "\n",
      "Audit complete. 8671 issues found in the dataset.\n",
      "81000 done\n",
      "82000 done\n",
      "83000 done\n",
      "84000 done\n",
      "85000 done\n",
      "86000 done\n",
      "87000 done\n",
      "88000 done\n"
     ]
    }
   ],
   "source": [
    "feats_2 = []\n",
    "classifications_2 = []\n",
    "imgs_2 = []\n",
    "pred_probs = []\n",
    "for i in range(70001, img_path_len):\n",
    "    img, probs = next(whole_ds_gen)\n",
    "    img = np.expand_dims(img, 0)\n",
    "    _f = featureExtraction.predict(img, verbose=0)\n",
    "    pred = m.predict(img, verbose=0)\n",
    "    feats_2.append(_f)\n",
    "    imgs_2.append(img)\n",
    "    pred_probs.append(pred)\n",
    "    \n",
    "    classifications_2.append(probs)\n",
    "    if i > 0 and i % 1000 == 0:\n",
    "        print(i, 'done')\n",
    "    if i > 0 and i % 10000 == 0:\n",
    "        data_to_clean = {'Images':np.squeeze(np.array(imgs_2)), 'Labels':np.array(classifications_2)}\n",
    "        lab = Datalab(data=data_to_clean, label_name=\"Labels\", image_key=\"Images\")\n",
    "        lab.find_issues(pred_probs=np.squeeze(np.array(pred_probs)), features=np.squeeze(np.array(feats_2)))\n",
    "        label_issues = lab.get_issues(\"label\")\n",
    "        label_issues.to_csv(f\"{i}_issues.csv\")\n",
    "        del(feats_2)\n",
    "        del(classifications_2)\n",
    "        del(imgs_2)\n",
    "        del(pred_probs)\n",
    "        feats_2 = []\n",
    "        classifications_2 = []\n",
    "        imgs_2 = []\n",
    "        pred_probs = []\n",
    "        \n",
    "\n",
    "data_to_clean = {'Images':np.squeeze(np.array(imgs_2)), 'Labels':np.array(classifications_2)}\n",
    "lab = Datalab(data=data_to_clean, label_name=\"Labels\", image_key=\"Images\")\n",
    "lab.find_issues(pred_probs=np.squeeze(np.array(pred_probs)), features=np.squeeze(np.array(feats_2)))\n",
    "label_issues = lab.get_issues(\"label\")\n",
    "label_issues.to_csv(f\"{i}_issues.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab\n",
    "#label_issues_df = label_issues.query(\"is_label_issue\").sort_values(\"label_score\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_full = feats+ feats_2\n",
    "classifications_full = classifications + classifications_2\n",
    "\n",
    "import pickle\n",
    "with open('featuresPickle.pickle', 'wb') as wf:\n",
    "    pickle.dump(feats_full, wf)\n",
    "\n",
    "with open('classesPickle.pickle', 'wb') as wc:\n",
    "    pickle.dump(classifications_full, wc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Done!')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
